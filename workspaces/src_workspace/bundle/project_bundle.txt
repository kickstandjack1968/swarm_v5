### FILE: clarifier.py ###
import json
import requests
import sys
from typing import Dict, List, Any

__all__ = ['run_clarifier', '__main__']

def load_config(config_path: str = "config_v2.json") -> Dict[str, Any]:
    with open(config_path, 'r') as f:
        return json.load(f)

def call_llm(config: Dict[str, Any], messages: List[Dict[str, str]]) -> str:
    url = config["model_config"]["multi_model"]["clarifier"]["url"]
    model = config["model_config"]["multi_model"]["clarifier"]["model"]
    api_type = config["model_config"]["multi_model"]["clarifier"]["api_type"]
    timeout = config["model_config"]["multi_model"]["clarifier"]["timeout"]
    
    headers = {"Content-Type": "application/json"}
    data = {
        "model": model,
        "messages": messages,
        "temperature": config["agent_parameters"]["clarifier"]["temperature"],
        "max_tokens": config["agent_parameters"]["clarifier"]["max_tokens"],
        "top_p": config["agent_parameters"]["clarifier"]["top_p"]
    }
    
    try:
        response = requests.post(f"{url}/chat/completions", headers=headers, json=data, timeout=timeout)
        response.raise_for_status()
        content = response.json()["choices"][0]["message"]["content"]
        if not content.strip():
            raise ValueError("Empty response from LLM")
        return content
    except Exception as e:
        print(f"LLM connection failed: {e}")
        raise

def parse_llm_response(response_text: str) -> Dict[str, Any]:
    try:
        # Try to parse as JSON
        result = json.loads(response_text)
        if isinstance(result, dict):
            return result
    except json.JSONDecodeError:
        pass
    
    # Fallback: look for structured content in text
    lines = response_text.strip().split('\n')
    parsed = {}
    
    # Simple heuristic parsing - look for sections
    current_section = None
    section_content = []
    
    for line in lines:
        if line.startswith('summary:'):
            current_section = 'summary'
            section_content = [line[8:].strip()]
        elif line.startswith('functional_requirements:'):
            current_section = 'functional_requirements'
            section_content = [line[24:].strip()]
        elif line.startswith('inputs:'):
            current_section = 'inputs'
            section_content = [line[7:].strip()]
        elif line.startswith('outputs:'):
            current_section = 'outputs'
            section_content = [line[8:].strip()]
        elif line.startswith('error_handling:'):
            current_section = 'error_handling'
            section_content = [line[15:].strip()]
        elif line.startswith('constraints:'):
            current_section = 'constraints'
            section_content = [line[12:].strip()]
        elif line.startswith('assumptions:'):
            current_section = 'assumptions'
            section_content = [line[12:].strip()]
        else:
            if current_section and line.strip():
                section_content.append(line.strip())
    
    # Join content for each section
    for key, value in parsed.items():
        parsed[key] = '\n'.join(value).strip()
    
    return parsed

def analyze_request(config: Dict[str, Any], user_request: str) -> Dict[str, Any]:
    system_prompt = (
        "You are a requirement analysis assistant. "
        "Analyze the following user request for ambiguities and suggest clarifying questions if needed. "
        "Respond with either:\n"
        "1. A JSON object with 'clear': true and a complete structured specification\n"
        "2. A JSON object with 'clear': false and 'questions': [list of questions]\n"
    )
    
    user_prompt = f"User request: {user_request}\n\nAnalyze this request for clarity and suggest any necessary clarifications."
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    response_text = call_llm(config, messages)
    return parse_llm_response(response_text)

def collect_user_answers(questions: List[str]) -> List[str]:
    print("CLARIFYING QUESTIONS:")
    for i, q in enumerate(questions, 1):
        print(f"{i}. {q}")
    
    print("\nPlease provide answers, then type DONE:")
    
    answers = []
    while True:
        answer = input()
        if answer.strip().upper() == "DONE":
            break
        answers.append(answer)
    
    return answers

def generate_final_spec(config: Dict[str, Any], user_request: str, answers: List[str]) -> Dict[str, Any]:
    system_prompt = (
        "You are a specification generator. "
        "Based on the original request and user's clarifications, produce a structured specification. "
        "Return only a valid JSON object with these fields:\n"
        "{\n"
        "  \"summary\": \"One paragraph description of what to build\",\n"
        "  \"functional_requirements\": [\"The system shall...\", \"The system shall...\"],\n"
        "  \"inputs\": [{\"name\": \"...\", \"type\": \"...\", \"description\": \"...\"}],\n"
        "  \"outputs\": [{\"name\": \"...\", \"type\": \"...\", \"description\": \"...\"}],\n"
        "  \"error_handling\": [\"How to handle X\", \"How to handle Y\"],\n"
        "  \"constraints\": [\"Python 3.8+\", \"No GUI required\"],\n"
        "  \"assumptions\": [\"Assumptions made based on answers or defaults\"]\n"
        "}\n"
    )
    
    user_prompt = f"Original request: {user_request}\n\nUser's clarifications:\n"
    for i, a in enumerate(answers, 1):
        user_prompt += f"{i}. {a}\n"
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": user_prompt}
    ]
    
    response_text = call_llm(config, messages)
    return parse_llm_response(response_text)

def run_clarifier(user_request: str, config_path: str = "config_v2.json") -> Dict[str, Any]:
    print("Clarifier: Analyzing request...")
    config = load_config(config_path)
    
    analysis_result = analyze_request(config, user_request)
    
    if analysis_result.get('clear', False):
        print("Clarifier: Requirements clear, generating specification...")
        return analysis_result
    
    # Request is unclear, ask questions
    print("Clarifier: Requirements unclear, asking questions...")
    questions = analysis_result.get('questions', [])
    
    # First round of questions
    answers = collect_user_answers(questions)
    
    # Re-analyze with answers
    print("Clarifier: Processing your answers...")
    second_analysis = analyze_request(config, f"{user_request}\n\nAnswers:\n" + "\n".join(answers))
    
    if not second_analysis.get('clear', False):
        # Still unclear, ask more questions
        print("Clarifier: Requirements still unclear, asking follow-up questions...")
        follow_up_questions = second_analysis.get('questions', [])
        answers.extend(collect_user_answers(follow_up_questions))
    
    # Generate final specification
    print("Clarifier: Requirements clear, generating specification...")
    final_spec = generate_final_spec(config, user_request, answers)
    
    print("Clarifier: Complete.")
    return final_spec

if __name__ == "__main__":
    test_request = "build me a CLI tool that parses CSV files"
    try:
        spec = run_clarifier(test_request)
        print(json.dumps(spec, indent=2))
    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)
### END FILE ###
